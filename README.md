# TalentScout AI Hiring Assistant
#
# TalentScout is an AI-powered hiring assistant chatbot that streamlines candidate screening and technical evaluation for technology roles. It guides users through a conversational flow, collects essential information, and generates personalized technical questions for each skill in the candidate's tech stack. The assistant adapts to user input, handles unexpected responses, and ensures a smooth, context-aware experience.
#
# ## How It Works
#
# 1. **Conversational Screening:**
#    - The chatbot collects candidate details (name, email, phone, experience, position, location, tech stack) through a friendly, step-by-step chat interface.
# 2. **Technical Question Generation:**
#    - For each skill in the tech stack, the app generates a technical question using a local LLM (Phi-3 Mini via Ollama).
#    - If the LLM fails or returns duplicate/irrelevant questions, the app uses a built-in local question bank for popular skills (e.g., React, FastAPI, C++, Python, etc.).
#    - If a skill is not recognized, the app provides a generic fallback question ("What is your experience with {skill}? Describe briefly.").
# 3. **Robust Fallbacks:**
#    - The app automatically retries question generation for each skill up to three times.
#    - If all attempts fail, the fallback logic ensures the candidate always receives a meaningful question or prompt.
# 4. **Session Management:**
#    - All candidate responses and session data are securely stored in MongoDB for later review.
# 5. **User Experience:**
#    - The UI is built with Streamlit, featuring a clean, mobile-friendly design and clear error/fallback messaging.
#
# ## Key Features
#
# - **LLM-powered and Local Question Bank:** Combines AI-generated and curated questions for reliability.
# - **Resilient to LLM Failures:** Always provides a relevant question, even if the LLM is unavailable or returns duplicates.
# - **Strict Input Validation:** Ensures all candidate data is well-formed and meaningful.
# - **Customizable:** Easily extend the local question bank or adjust validation rules.
# - **Secure and Private:** Candidate data is stored locally and never shared externally.
#

## Project Overview
TalentScout is an AI-powered hiring assistant chatbot designed to streamline candidate screening and technical evaluation. It guides users through a conversational flow, collects essential information, and generates personalized technical questions for each skill in the candidate's tech stack. The assistant adapts to user input, handles unexpected responses, and ensures a smooth, context-aware experience.

## Installation Instructions

### Prerequisites
- Python 3.10+
- Node.js (for optional server.js features)
- MongoDB (local or cloud instance)
- [Ollama](https://ollama.com/) (for local LLM support)

### Setup Steps
1. **Clone the repository:**
   ```sh
   git clone <repo-url>
   cd PGAGI
   ```
2. **Install Python dependencies:**
   ```sh
   pip install -r requirements.txt
   ```
3. **Install Node.js dependencies (if using server.js):**
   ```sh
   npm install
   ```
4. **Configure environment variables:**
   - Copy `.env.example` to `.env` and set your MongoDB connection string and other variables.
5. **Start MongoDB:**
   - Ensure your MongoDB instance is running locally or accessible via your connection string.
6. **Run the Streamlit app:**
   ```sh
   streamlit run app.py
   ```

## Usage Guide
- Open the app in your browser (Streamlit will provide a local URL).
- Follow the chatbot prompts to enter your name, email, phone, experience, position, location, and tech stack.
- For each skill, answer the technical question generated by the AI.
- If a question cannot be generated, you can retry, skip, or rephrase the skill.
- Type 'exit' to end the session.

## Technical Details
- **Libraries Used:**
  - `streamlit` (UI and state management)
  - `pymongo` (MongoDB integration)
  - `vaderSentiment` (sentiment analysis)
  - `dotenv` (environment variable management)
  - `re` (regex validation)
- **Model Details:**
  - Uses local LLM via Ollama (Phi-3 Mini) for prompt-based question generation and validation.
  - Fallback responses if LLM is unavailable.
- **Architecture:**
  - Stateless UI with Streamlit forms and session state.
  - State machine for conversation flow.
  - MongoDB for session and candidate info persistence.

## Prompt Design
- Prompts are crafted to:
  - Validate user input strictly (e.g., name, email, phone).
  - Generate technical questions specific to each skill, avoiding duplicates.
  - Handle fallback and clarification when input is invalid or ambiguous.
  - Offer retry/skip/rephrase options for technical question generation failures.

## Challenges & Solutions
**Duplicate or Irrelevant Questions:**
  - Solution: Track previously asked questions and retry generation. If the LLM returns duplicates or irrelevant questions, use the local question bank or a generic fallback prompt.
**LLM Unavailability or Failure:**
  - Solution: Provide fallback responses from the local question bank for popular skills, and a generic prompt for others. The app always provides a meaningful question, even if the LLM is unavailable.
**User Input Validation:**
  - Solution: Strict regex-based validation for all fields (name, email, phone, experience, position, location, tech stack).
**Conversation Flow:**
  - Solution: State machine manages context and transitions, ensuring a coherent user experience.

## Contact & Support
For issues or feature requests, please open an issue on GitHub or contact the maintainer.
# TalentScout Hiring Assistant

An intelligent AI-powered chatbot for initial candidate screening in technology recruitment. Built with Streamlit and OpenAI's GPT models.

## üöÄ Features

### Core Functionality
- **Interactive Candidate Screening**: Streamlined conversation flow for gathering candidate information
- **Tech Stack Assessment**: Dynamic technical question generation based on candidate's technology stack
- **Intelligent Conversation Management**: Context-aware responses with fallback mechanisms
- **Data Privacy Compliance**: Secure handling of candidate information
- **Professional UI/UX**: Clean, intuitive interface built with Streamlit

### AI/LLM Integration
- **Primary**: Ollama with Phi-3 Mini model for local, private AI responses
- **Fallback**: Hugging Face Transformers for offline capability
- **Backup**: Rule-based responses ensure the app always works
- **No API Keys Required**: Completely self-contained solution

### Technical Capabilities
- **Local LLM Support**: Runs entirely on your machine without external API calls
- **Dynamic Question Generation**: Tailored technical questions for 9+ technology domains
- **Input Validation**: Email, phone number, and data format validation
- **Session Management**: Persistent conversation state and progress tracking
- **Responsive Design**: Mobile-friendly interface with custom styling

## üèóÔ∏è Architecture

### Project Structure
```
hiring-assistant/
‚îú‚îÄ‚îÄ app.py                 # Main Streamlit application
‚îú‚îÄ‚îÄ utils.py              # Utility functions and data classes
‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îú‚îÄ‚îÄ .env.example         # Environment variables template
‚îú‚îÄ‚îÄ data/                # Directory for candidate data storage
‚îú‚îÄ‚îÄ README.md            # This file
‚îî‚îÄ‚îÄ assets/              # Static assets (if needed)
```

### Key Components

1. **TalentScoutChatbot Class**: Main chatbot logic with state management
2. **CandidateInfo DataClass**: Structured candidate data storage
3. **TechnicalQuestionBank**: Repository of technology-specific questions
4. **DataHandler**: Secure data storage and retrieval
5. **PromptTemplates**: Optimized prompts for different scenarios

## üõ†Ô∏è Installation & Setup

### Prerequisites
- Python 3.8 or higher
- **Option 1**: Ollama installed with Phi-3 model (recommended)
- **Option 2**: Internet connection for Hugging Face models
- **Option 3**: None required (uses fallback responses)
- Git (for version control)

### Step-by-Step Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/tarunpatil01/PGAGI.git
   cd PGAGI/hiring-assistant
   ```

2. **Set up Python environment**
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up AI Model (Choose one option)**

   **Option A: Ollama (Recommended)**
   ```bash
   # Install Ollama from https://ollama.com/download
   # Then run:
   ollama pull phi3:mini
   ollama serve
   ```

   **Option B: Run setup script**
   ```bash
   python setup_ollama.py
   ```

   **Option C: Use without local AI**
   ```bash
   # The app will use fallback responses
   # No additional setup needed
   ```

5. **Create environment file**
   ```bash
   cp .env.example .env
   # Edit .env if needed (default settings work for most cases)
   ```

6. **Run the application**
   ```bash
   streamlit run app.py
   ```

7. **Access the application**
   - Open your browser and go to `http://localhost:8501`
   - The chatbot interface will be ready for candidate interactions

## üéØ Usage Guide

### For Candidates
1. **Start Conversation**: The chatbot greets you and asks for your name
2. **Provide Information**: Share your contact details, experience, and desired position
3. **Declare Tech Stack**: List your programming languages, frameworks, and tools
4. **Answer Technical Questions**: Respond to 3-5 tailored technical questions
5. **Complete Screening**: Review your information and receive next steps

### For Recruiters/Administrators
1. **Monitor Sessions**: Use the sidebar to track candidate progress
2. **Review Data**: Candidate information is stored securely in the `data/` directory
3. **Reset Sessions**: Use the "Start New Session" button to clear the conversation
4. **Customize Questions**: Modify the `TechnicalQuestionBank` in `utils.py`

## üîß Configuration

### Supported Technologies
The chatbot can generate questions for:
- **Programming Languages**: Python, JavaScript, Java
- **Frontend**: React, HTML/CSS
- **Backend**: Node.js, Django, Flask
- **Databases**: SQL, PostgreSQL, MongoDB
- **Cloud**: AWS, Azure, GCP
- **DevOps**: Docker, Kubernetes, Git
- **And more...

### Customization Options
1. **Question Bank**: Add/modify questions in `utils.py`
2. **Conversation Flow**: Adjust states in `app.py`
3. **UI Styling**: Modify CSS in the `main()` function
4. **Validation Rules**: Update validation functions in `utils.py`

## üîê Security & Privacy

### Data Protection
- **Local Storage**: All candidate data stored locally by default
- **No External Sharing**: Information not shared with third parties
- **Session Isolation**: Each session is independent and secure
- **Input Validation**: All inputs validated and sanitized

### Privacy Compliance
- **GDPR Ready**: Designed with privacy regulations in mind
- **Data Minimization**: Only collects necessary information
- **Secure Processing**: Uses encrypted API communication
- **Audit Trail**: Conversation logs for quality assurance

## üìä Technical Specifications

### Technology Stack
- **Frontend**: Streamlit (Python web framework)
- **Backend**: Python 3.8+
- **AI/ML**: 
  - Primary: Ollama with Phi-3 Mini (local)
  - Fallback: Hugging Face Transformers
  - Backup: Rule-based responses
- **Data Storage**: JSON files (local), extensible to databases
- **Deployment**: Local development, cloud-ready

### Dependencies
```
streamlit               # Web framework
requests               # HTTP client
pandas                 # Data manipulation
python-dotenv         # Environment management
ollama                # Local LLM interface
transformers          # Hugging Face models
torch                 # Deep learning framework
accelerate           # Model optimization
sentence-transformers # Text embeddings
```

## üöÄ Deployment

### Local Development
```bash
streamlit run app.py
```

### Production Deployment

#### Option 1: Streamlit Cloud
1. Push code to GitHub repository
2. Connect to Streamlit Cloud
3. Add environment variables
4. Deploy automatically

#### Option 2: AWS EC2
```bash
# Install dependencies
sudo yum update -y
sudo yum install python3 python3-pip -y

# Clone and setup
git clone <repository-url>
cd hiring-assistant
pip3 install -r requirements.txt

# Run with nohup for background execution
nohup streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &
```

#### Option 3: Docker
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

## üß™ Testing

### Manual Testing Checklist
- [ ] Greeting and name collection
- [ ] Information gathering (email, phone, experience)
- [ ] Tech stack input and validation
- [ ] Technical question generation
- [ ] Conversation flow and state management
- [ ] Error handling and fallback responses
- [ ] Session reset functionality

### Common Test Scenarios
1. **Happy Path**: Complete full screening process
2. **Invalid Inputs**: Test email/phone validation
3. **Edge Cases**: Empty tech stack, long responses
4. **Conversation Endings**: "goodbye", "exit" keywords
5. **Error Recovery**: API failures, network issues

## üîç Troubleshooting

### Common Issues

1. **OpenAI API Key Error**
   - Ensure your API key is valid and has credits
   - Check the `.env` file configuration

2. **Streamlit Import Error**
   - Verify virtual environment is activated
   - Reinstall dependencies: `pip install -r requirements.txt`

3. **Port Already in Use**
   - Use different port: `streamlit run app.py --server.port 8502`

4. **Tech Stack Questions Not Generated**
   - Check if technology is supported in `TechnicalQuestionBank`
   - Verify API response format

## üé® Customization Examples

### Adding New Technologies
```python
# In utils.py, add to TechnicalQuestionBank
"flutter": [
    TechnicalQuestion("Flutter", "What is the difference between StatefulWidget and StatelessWidget?", "basic"),
    TechnicalQuestion("Flutter", "How do you manage state in Flutter applications?", "intermediate"),
]
```

### Modifying Question Difficulty
```python
# Adjust difficulty distribution in get_questions_for_tech_stack
def get_questions_for_tech_stack(self, tech_stack: List[str], total_questions: int = 5):
    # 60% basic, 30% intermediate, 10% advanced
    basic_count = int(total_questions * 0.6)
    intermediate_count = int(total_questions * 0.3)
    advanced_count = total_questions - basic_count - intermediate_count
```

### Custom Styling
```python
# In app.py, modify the CSS
st.markdown("""
<style>
.custom-header {
    background: linear-gradient(90deg, #your-color1, #your-color2);
    /* Add your custom styles */
}
</style>
""", unsafe_allow_html=True)
```

## üìà Performance Optimization

### Response Time Optimization
- **Caching**: Implement Streamlit caching for question generation
- **API Calls**: Batch API requests when possible
- **Question Bank**: Use local question bank as fallback

### Scalability Considerations
- **Database Integration**: Replace JSON files with SQL/NoSQL database
- **Load Balancing**: Use multiple OpenAI API keys for high traffic
- **Async Processing**: Implement async operations for better performance

## ü§ù Contributing

### Development Guidelines
1. Follow PEP 8 style guide
2. Add docstrings to all functions
3. Include type hints
4. Write comprehensive tests
5. Update documentation

### Pull Request Process
1. Fork the repository
2. Create feature branch
3. Make changes with tests
4. Submit pull request
5. Code review and merge

## üìù Changelog

### Version 1.0.0 (Current)
- Initial release with core functionality
- Support for 9+ technology domains
- Streamlit-based user interface
- OpenAI GPT integration
- Data privacy compliance

### Planned Features
- Multi-language support
- Advanced analytics dashboard
- Integration with ATS systems
- Video/voice interview capabilities
- Machine learning-based candidate ranking

## üìÑ License

This project is licensed under the MIT License. See LICENSE file for details.

## üìû Support

For questions, issues, or contributions:
- **Email**: careers@talentscout.com
- **GitHub Issues**: [Create an issue](https://github.com/tarunpatil01/PGAGI/issues)
- **Documentation**: This README file

## üôè Acknowledgments

- OpenAI for GPT API
- Streamlit team for the web framework
- Python community for excellent libraries
- Contributors and beta testers

---

**TalentScout Hiring Assistant** - Making technical recruitment more efficient and candidate-friendly through AI-powered conversations.
